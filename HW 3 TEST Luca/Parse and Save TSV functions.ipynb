{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse URL's from html 3\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse all the info that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title (soup):\n",
    "    # We get the title of the movie\n",
    "    title = soup.select(\"#firstHeading\")[0].text\n",
    "    return title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intro(soup):\n",
    "    # In this part we get the INTRO of the movie\n",
    "    try:\n",
    "        sec = soup.findAll('p')[0]\n",
    "        if sec == soup.find(\"p\", class_=\"mw-empty-elt\"):\n",
    "            section_intro = soup.findAll('p')[1]\n",
    "        else:\n",
    "            section_intro = sec\n",
    "        nextNode = section_intro\n",
    "        intro = []\n",
    "        intro.append(nextNode.text)\n",
    "\n",
    "        while True:\n",
    "            nextNode = nextNode.find_next_sibling()\n",
    "            if nextNode and nextNode.name == 'p':\n",
    "                intro.append(nextNode.text)\n",
    "\n",
    "            else:\n",
    "                break          \n",
    "        intro_s = \"\"\n",
    "\n",
    "        for ele in intro: \n",
    "            intro_s += ele\n",
    "            \n",
    "        return intro_s\n",
    "    \n",
    "    except IndexError:\n",
    "        intro_s = None\n",
    "        return intro_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot (soup):\n",
    "    try:    \n",
    "        # In this part we get the PLOT of the movie\n",
    "        sec = soup.findAll('h2')[0]\n",
    "        if sec.text == 'Contents' or sec.text == 'Cast':\n",
    "            section_plot = soup.findAll('h2')[1]\n",
    "            if section_plot.text == 'Cast':\n",
    "                section_plot = soup.findAll('h2')[1]\n",
    "        else:\n",
    "            section_plot = sec\n",
    "        nextNode = section_plot.find_next_sibling('p')\n",
    "\n",
    "        plot = []\n",
    "        while True:\n",
    "\n",
    "            if nextNode and nextNode.name == 'p':\n",
    "                plot.append(nextNode.text)\n",
    "                nextNode = nextNode.find_next_sibling()\n",
    "            else:\n",
    "                break          \n",
    "        plot_s = \"\"\n",
    "\n",
    "        for ele in plot: \n",
    "            plot_s += ele\n",
    "        return plot_s\n",
    "    except IndexError:\n",
    "        plot_s = None\n",
    "        return plot_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infobox(soup):\n",
    "    try:\n",
    "        table = soup.find('table', class_='infobox vevent')\n",
    "        nextNode = table\n",
    "        table2 = table.find_all('tr')\n",
    "\n",
    "        dic={}\n",
    "        for th in table2[1:]:\n",
    "            if th.find('th'):            \n",
    "                dic[th.find('th').text] = th.find('td').get_text(strip=True, separator='|').split('|')\n",
    "\n",
    "        standard_dic = {\n",
    "        \"Directed by\" : \"\",\n",
    "        \"Produced by\": \"\",\n",
    "        \"Written by\": \"\",\n",
    "        \"Starring\": \"\",\n",
    "        \"Music by\": \"\", \n",
    "        \"Release date\": \"\",\n",
    "        \"Running time\": \"\",\n",
    "        \"Country\": \"\",\n",
    "        \"Language\": \"\",\n",
    "        \"Budget\": \"\"} \n",
    "\n",
    "        # In this part we check if the keys of the infobox are the same as the ones requested   \n",
    "        shared_items = {k: dic[k] for k in dic.keys() & standard_dic.keys()}\n",
    "\n",
    "\n",
    "\n",
    "        # We transform the list into strings\n",
    "        for k, v in shared_items.items():\n",
    "            shared_items[k] = \", \".join(v)\n",
    "\n",
    "        # Difference, we would like to find the missing INFO of this movie\n",
    "        value = { k : standard_dic[k] for k in set(standard_dic) - set(dic) }\n",
    "\n",
    "        # Replace missing INFO with NaN\n",
    "        value = {k: None if not v else v for k, v in value.items() }\n",
    "\n",
    "\n",
    "        # Let's combine these two dictionaries\n",
    "        final = dict(shared_items, **value)\n",
    "\n",
    "        return final\n",
    "    \n",
    "    except AttributeError:\n",
    "        final = {\n",
    "        \"Directed by\" : None,\n",
    "        \"Produced by\": None,\n",
    "        \"Written by\": None,\n",
    "        \"Starring\": None,\n",
    "        \"Music by\": None, \n",
    "        \"Release date\": None,\n",
    "        \"Running time\": None,\n",
    "        \"Country\": None,\n",
    "        \"Language\": None,\n",
    "        \"Budget\": None} \n",
    "        \n",
    "        \n",
    "        return final\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the info into a TSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import csv\n",
    "\n",
    "dir_path = r\"C:\\Users\\Luca\\Desktop\\-\\Universit√†\\Magistrale\\Primo anno\\Primo semestre\\ADM\\Homeworks\\Homework #3\\articles\"\n",
    "\n",
    "c = 0   \n",
    "for file_name in glob.glob(os.path.join(dir_path, \"*.html\")):\n",
    "    \n",
    "    with open(file_name, encoding=\"utf8\") as html_file:\n",
    "        soup = BeautifulSoup(html_file)\n",
    "        t = title(soup)\n",
    "        i = intro(soup)\n",
    "        p = plot(soup)\n",
    "        \n",
    "        \n",
    "        # Write TSV file for each movie, we create a unique dictionary\n",
    "        dic_title = {'Title' : t}\n",
    "        dic_intro = {'Intro' : i}\n",
    "        dic_plot  = {'Plot' : p}\n",
    "        dic_infobox = infobox(soup)\n",
    "        \n",
    "        temp = dict(dic_title, **dic_intro) \n",
    "        temp2 = dict(temp, **dic_plot)\n",
    "        final = dict(temp2, **dic_infobox) # it's the unique dictionary we were talking of before\n",
    "        \n",
    "        with open(r'TSV\\article_{}.tsv'.format(c), 'wt', encoding=\"utf8\") as out_file:\n",
    "            tsv_writer = csv.DictWriter(out_file, final.keys(), delimiter ='\\t')\n",
    "            tsv_writer.writeheader()\n",
    "            tsv_writer.writerow(final)\n",
    "    c += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
